# MySLURM — Low Level Design (Updated)

> Purpose: A single, presentation-ready low-level design document you can show your manager. It describes the full data flow from SLURM → poller → Redis/Oracle/NFS → FastAPI → React, includes schemas, Redis keys, API contracts, poller pseudocode, retention policies, monitoring, deployment, and an operations runbook.

---

## 1) Executive Summary

* Poll every **5 minutes** (per cluster) using a **Poller** that queries SLURM (CLI preferred: `squeue`, `sinfo`, `sacct`).
* Poller writes **fresh snapshots** to **Redis** (overwrite, TTL 300s) for instant UI reads.
* Poller **upserts current state** into **Oracle** (`current_job`) and **inserts** into `job_state_changes` **only when meaningful changes occur** (state change or resource delta). Oracle holds a **30-day warm window** and is partitioned by day for cheap pruning.
* Poller appends **raw snapshots** into **Parquet files on NFS** (hourly files, partitioned by cluster/year/month/day/hour) for cold storage and long-term analytics.
* FastAPI reads from Redis for live views and from Oracle (or Trino over Parquet) for historical queries. Backend never queries SLURM directly on UI requests.

**Benefits:** Protects `slurmctld` from load, keeps UI near-real-time, minimizes Oracle growth, provides durable raw data for analytics.

---

## 2) High-level Data Flow

```
[SLURM (slurmctld)]
       |
   (poll every 5m)
       v
    POLLER (1 per cluster)
   /   |      \
  v    v       v
Redis  Oracle  NFS (Parquet)
(5 min) (30d)   (raw archive)
  |      |        |
  +------v--------+
         |
     FastAPI Backend
         |
      React Frontend
```

* Poller => Redis, Oracle, NFS
* FastAPI => reads Redis (primary) → filters & returns per-user data
* FastAPI => reads Oracle or Trino for historical analytics

**Important rule:** *Redis is written only by the Poller; the backend reads from Redis and may invalidate keys on admin actions. Redis does not fetch from Oracle.*

---

## 3) Component Responsibilities

### 3.1 Poller

* Runs on a node with SLURM CLI access (or via slurmrestd as fallback).
* Poll interval configurable (default `300s`).
* Writes to:

  * Redis: cluster-wide snapshots (overwrite)
  * Oracle: upsert `current_job` + append `job_state_changes` on meaningful change
  * NFS Parquet: append raw snapshots hourly
* Emits Prometheus metrics and logs

### 3.2 Redis

* In-memory cache for live UI. Keys contain full cluster snapshots (not per-user caches).
* TTLs: 300s (± jitter). Poller overwrites keys every run.

### 3.3 Oracle

* Stores warm/hot data (30-day window), aggregated tables, audit logs, and precomputed materialized views.
* Partitioned by day for `job_state_changes` and other append-only tables. Use `MERGE` for `current_job`.

### 3.4 NFS (Parquet)

* Raw JSON → Parquet conversion; hourly files, partitioned by cluster/date/hour.
* Used by Trino / Spark for deep analytics.

### 3.5 FastAPI

* Reads Redis for fast responses; queries Oracle for history; exposes admin actions (scancel) via privileged execution on admin host.
* WebSocket for push notifications.

### 3.6 React Frontend

* Uses React Query for caching; WebSocket for notifications; reads only FastAPI endpoints.

---

## 4) Redis Key Design

| Key pattern                |                                       Description |     TTL |
| -------------------------- | ------------------------------------------------: | ------: |
| `cluster:{c}:jobs:latest`  |               Full jobs snapshot JSON for cluster |    300s |
| `cluster:{c}:nodes:latest` |                                Node snapshot JSON |    300s |
| `cluster:{c}:dashboard`    |      Precomputed dashboard cards (counts, gauges) | 60–300s |
| `mv_cache:{hash}`          | Cached heavy analytics result keyed by query hash |  5m–60m |
| `notifications:{user}`     |  List or counter of unread notifications (no TTL) |       - |

**Cache policy:** Poller writes/overwrites. FastAPI reads. Admin actions invalidate relevant keys.

---

## 5) Oracle Schema (Core Tables & DDL)

### 5.1 `current_job` (one row per active job — upsert)

```sql
CREATE TABLE current_job (
  job_id NUMBER PRIMARY KEY,
  cluster_name VARCHAR2(100),
  user_name VARCHAR2(100),
  job_name VARCHAR2(4000),
  partition VARCHAR2(100),
  state VARCHAR2(50),
  submit_time TIMESTAMP WITH TIME ZONE,
  start_time TIMESTAMP WITH TIME ZONE,
  end_time TIMESTAMP WITH TIME ZONE,
  cpus NUMBER,
  mem_mb NUMBER,
  nodes VARCHAR2(1000),
  last_polled TIMESTAMP WITH TIME ZONE,
  row_hash VARCHAR2(64),
  raw_json CLOB
);
CREATE INDEX idx_current_job_user ON current_job(user_name);
```

### 5.2 `job_state_changes` (append-only — partition by day)

```sql
CREATE TABLE job_state_changes (
  id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  job_id NUMBER,
  cluster_name VARCHAR2(100),
  user_name VARCHAR2(100),
  prev_hash VARCHAR2(64),
  new_hash VARCHAR2(64),
  changed_at TIMESTAMP WITH TIME ZONE,
  cpus NUMBER,
  mem_mb NUMBER,
  nodes VARCHAR2(1000),
  reason VARCHAR2(1000),
  raw_json CLOB
);
CREATE INDEX idx_jsc_job ON job_state_changes(job_id);
CREATE INDEX idx_jsc_user ON job_state_changes(user_name);
-- Partition this table by day for cheap pruning
```

### 5.3 Aggregates and audit tables

```sql
CREATE TABLE hourly_user_summary (id NUMBER PRIMARY KEY, cluster_name VARCHAR2(100), username VARCHAR2(100), hour_ts TIMESTAMP WITH TIME ZONE, cpu_hours NUMBER, jobs_started NUMBER, jobs_completed NUMBER);
CREATE TABLE admin_audit (id NUMBER PRIMARY KEY, actor VARCHAR2(100), action VARCHAR2(100), object_type VARCHAR2(50), object_id VARCHAR2(200), details CLOB, created_at TIMESTAMP WITH TIME ZONE DEFAULT SYSTIMESTAMP);
CREATE TABLE user_notifications (id NUMBER PRIMARY KEY, username VARCHAR2(100), cluster_name VARCHAR2(100), message VARCHAR2(4000), created_at TIMESTAMP WITH TIME ZONE DEFAULT SYSTIMESTAMP, read_flag CHAR(1) DEFAULT 'N');
```

**Retention:** Partition `job_state_changes` by day and drop partitions older than 30 days via scheduled job.

---

## 6) Parquet on NFS: Layout & Best Practices

**File path convention** (hourly files):

```
/nfs/myslurm/cluster={cluster}/year={YYYY}/month={MM}/day={DD}/hour={HH}/part-{nn}.parquet
```

**Write pattern:**

* Poller buffers poll JSON in memory or local disk.
* Flush hourly to Parquet using PyArrow/Pandas with Snappy or ZSTD compression.
* Write to a temp file, then atomic `mv` to final NFS path.
* Avoid many tiny files; use hourly or 10–15min combined files.

**Why Parquet:** Columnar, compact, efficient for analytics; works with Trino/Spark.

---

## 7) Poller — Full Detailed Design & Pseudocode

### Responsibilities

* Query SLURM (CLI preferred)
* Produce: Redis snapshots, Oracle upserts/inserts, Parquet append
* Emit metrics (Prometheus)
* Handle retries, errors, and monitoring

### Poller Pseudocode (production-ready)

```python
# poller.py (simplified outline)
import time, json, hashlib
from datetime import datetime, timezone
import redis, cx_Oracle, pyarrow as pa, pyarrow.parquet as pq

POLL_INTERVAL = 300
REDIS_EX = 300

# Setup clients
r = redis.Redis(host='localhost',port=6379)
oracle_pool = cx_Oracle.SessionPool(user,pw,dsn,min=2,max=10)

def normalize_job(job):
    norm = {
        'job_id': int(job['job_id']),
        'user': job['user_name'],
        'state': job['state'],
        'cpus': job.get('cpus',0),
        'mem_mb': job.get('mem',0),
        'nodes': sorted(job.get('node_list', []))
    }
    return json.dumps(norm, separators=(',',':'), sort_keys=True)

def job_hash(norm_str):
    import hashlib
    return hashlib.sha256(norm_str.encode()).hexdigest()

def poll_once(cluster):
    polled_at = datetime.now(timezone.utc)
    jobs = run_cmd_json(['squeue','--json'])['jobs']
    nodes = run_cmd_json(['sinfo','--json'])

    # 1) Redis write (overwrite)
    r.set(f"cluster:{cluster}:jobs:latest", json.dumps(jobs), ex=REDIS_EX)
    r.set(f"cluster:{cluster}:nodes:latest", json.dumps(nodes), ex=REDIS_EX)

    # 2) Oracle upsert + change detection (batch approach)
    conn = oracle_pool.acquire()
    cursor = conn.cursor()

    job_ids = [int(j['job_id']) for j in jobs]
    # fetch existing hashes in one query
    existing = fetch_hashes(cursor, job_ids)  # returns dict job_id->hash

    to_upsert = []
    to_changes = []
    for job in jobs:
        jid = int(job['job_id'])
        norm = normalize_job(job)
        h = job_hash(norm)
        if jid not in existing:
            to_changes.append((jid, None, h, polled_at, json.dumps(job)))
        else:
            if existing[jid] != h:
                to_changes.append((jid, existing[jid], h, polled_at, json.dumps(job)))
        to_upsert.append(build_upsert_row(job, h, polled_at))

    bulk_merge_current_job(cursor, to_upsert)
    bulk_insert_job_state_changes(cursor, to_changes)
    conn.commit()
    oracle_pool.release(conn)

    # 3) buffer raw JSON and flush hourly to Parquet on NFS
    buffer_append(cluster, polled_at, jobs, nodes)

# main loop
while True:
    for cluster in CLUSTERS:
        try:
            poll_once(cluster)
        except Exception as e:
            log_error(e)
    time.sleep(POLL_INTERVAL)
```

**Optimizations:**

* Use bulk `executemany` for inserts
* Fetch existing hashes in a single query, not per-job
* Use cx_Oracle `SessionPool` for efficient DB connections
* Use Prometheus metrics for poll duration, errors, rows processed

---

## 8) FastAPI — API Contracts & Behaviors

### Authentication & Authorization

* SSO (OIDC) / corporate SSO → JWT
* `get_current_user()` maps JWT → username + roles
* Admin endpoints require `admin` role

### Important endpoints

```
GET  /api/v1/user/dashboard?cluster={c}
  -> reads Redis cluster:{c}:dashboard

GET  /api/v1/user/jobs?cluster={c}&page=1&page_size=50
  -> reads Redis cluster:{c}:jobs:latest, filters by username, supports pagination (in-memory keyset)

GET  /api/v1/user/job/{job_id}
  -> tries Redis job snapshot (fast) else Oracle current_job / job_state_changes

POST /api/v1/user/job/submit
  -> submit via privileged submission host (not FastAPI unless hosted on head node)

GET  /api/v1/admin/cluster/{c}/health
  -> reads Redis cluster:{c}:nodes:latest + Oracle aggregates

POST /api/v1/admin/job/{job_id}/action
  -> validate admin, log into admin_audit, call privileged scancel or slurmrestd admin endpoint, invalidate Redis keys
```

**Caching policy:** FastAPI reads Redis for live; if Redis missing, it reads Oracle for summaries; only poller writes Redis.

**WebSockets:** `/api/ws/notifications` to push alerts (poller triggers notify insert and optionally broadcasts)

---

## 9) Frontend Data Flow (per user)

1. React requests `GET /api/v1/user/dashboard?cluster=A`.
2. FastAPI reads Redis `cluster:A:dashboard`, returns JSON with `last_polled` timestamp.
3. React displays cards, slot gauges, and `Last polled` indicator.
4. User clicks Jobs → React requests `GET /api/v1/user/jobs?cluster=A&page=1`, FastAPI reads `cluster:A:jobs:latest` from Redis, filters `user_name==current_user` in-memory, returns paginated results.
5. User expands job details → `GET /api/v1/user/job/{id}` → FastAPI returns job detail from Redis or Oracle if not present.
6. Notifications are delivered via WebSocket when poller inserts an alert into `user_notifications` or when admin triggers action.

---

## 10) Retention, Compaction & Housekeeping

* **Oracle warm window:** 30 days. Implement daily partition drop for `job_state_changes` older than 30 days.
* **Parquet on NFS:** keep 1–3 years (policy-based). Consider offloading to cold storage after 1 year.
* **Redis:** TTL 300s; poller overwrites every 5 minutes. If poller dies, UI shows `last_polled` and no stale writes are accepted.
* **Compaction:** hourly ETL computes `hourly_user_summary` and `daily_cluster_summary` from either Oracle recent window or Parquet cold store.

---

## 11) Monitoring & Alerts

**Poller:** last_poll_ts, poll_duration_seconds, poll_errors_total (Prometheus) — alert if last_poll_ts > 2 * POLL_INTERVAL

**Redis:** memory usage, hit_rate, miss_rate — alert if miss_rate high or memory > threshold

**Oracle:** tablespace usage, slow queries, connection pool exhaustion

**NFS:** disk usage (>70% warn, >90% critical)

**SLURM:** if poller detects slurmctld slow responses — alert ops

---

## 12) Security & Operational Controls

* Run pollers on secured hosts with restricted network access to SLURM controllers.
* Admin actions executed from a privileged host and logged to `admin_audit`.
* Use JWT + SSO for UI auth; RBAC for API endpoints.
* Store secrets in Vault; never in plaintext.

---

## 13) Deployment & Scaling Notes

* Run one poller per cluster (sharded) as systemd service or container with `--network=host` if CLI required.
* FastAPI behind Nginx or a gateway; run multiple replicas when load rises.
* Redis with Sentinel for HA in production.
* Oracle managed or RAC for high availability.
* Consider Trino if you need interactive analytics across Parquet.

---

## 14) Runbook (for Manager)

**Start-up:**

1. Start Oracle and ensure partitions/schemas present.
2. Start Redis and FastAPI backend.
3. Start Poller for each cluster. Verify `last_polled` metrics.

**If UI stale:**

1. Check poller logs for errors.
2. Check Redis key `cluster:{c}:jobs:latest` exists.
3. Check `last_polled` metric.

**If Oracle grows:**

1. Ensure partition drops run.
2. Check `job_state_changes` insertion pattern — are we inserting too often? Tune change detection.
3. Increase prune window or archive to Parquet.

**If NFS slow:**

1. Switch to local temp write then rsync to NFS.
2. Consider migrating Parquet storage to object store (S3/Ceph) and use Trino.

---

## 15) Appendix (Useful Code & References)

* Poller pseudocode above (Section 7)
* MERGE example for `current_job` (Section 5)
* Parquet write pattern: PyArrow `pq.write_table(table, path, compression='ZSTD')`
* Redis client: use `redis-py` with connection pooling

---

## 16) UI Mockup

You can preview the UI mockup image generated earlier here:

`/mnt/data/A_screenshot_of_a_web_dashboard_titled_"MySLURM"_f.png`

---

## 17) Suggested Next Deliverables (pick one)

* Full Poller implementation (Python) with cx_Oracle bulk-upsert + Parquet flush.
* FastAPI skeleton with Redis integration + endpoints + WebSocket notifications.
* Oracle DDL scripts + partition management PL/SQL.
* React scaffold pages + React Query hooks.

Tell me which one you want first and I will generate the code/artifact.

---

*Document generated on: 2025-11-26*
